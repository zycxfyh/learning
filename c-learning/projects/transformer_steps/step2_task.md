# 🎯 任务书：第二步 - 打造 Transformer 的“心脏” (MatMul)

## 目标
实现矩阵乘法函数 `matmul`。这是神经网络中最耗时、最核心的计算过程。

## 任务背景
在 Transformer 里：
- **Q, K, V 的生成**是矩阵乘法。
- **Attention 的计算**是矩阵乘法。
- **前馈神经网络 (FFN)** 还是矩阵乘法。
掌握了它，你就掌握了线性代数在 AI 里的秘密。

## 关键挑战：坐标映射
我们的内存是**一维线性**的（像地上的长条），但矩阵是**二维**的。
- 坐标 `(row, col)` 对应的位置是：`index = row * cols + col`。
- **比如**：一个 3 列的矩阵，`(1, 2)` 位置在索引 `1 * 3 + 2 = 5` 的地方。

## 算法逻辑 (三重循环)
```c
for i in A的行:
    for j in B的列:
        sum = 0
        for k in A的列(也是B的行):
            sum += A[i][k] * B[k][j]
        C[i][j] = sum
```

---
## 检查标准
手动计算两个 2x2 矩阵的乘积，并与你的程序结果对比。
```bash
gcc step2_matmul_lab.c -o lab2 && ./lab2
```
